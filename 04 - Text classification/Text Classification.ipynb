{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [slavko.zitnik@fri.uni-lj.si](mailto:slavko.zitnik@fri.uni-lj.si) for any comments.</sub>\n",
    "\n",
    "Text classification is normally referred to as deriving a class for a text document according to precalculated features. A text document can be a paragraph, tweet post, sentence, forum post, ... On the other hand, text tagging problems deal with classification of tokens in a sequence. Sequences can represent tokens, sentences, forum thread, characters, ...\n",
    "\n",
    "<img src=\"classifiers.png\" width=\"600\">\n",
    "\n",
    "## Text Classification\n",
    "\n",
    "Some examples of text classification problems are text categorization, spam detection, sentiment analysis, language identification, ... Definition of a problem:\n",
    "\n",
    "**Input:**\n",
    "* a document $d \\in D$\n",
    "* a fixed set of classes $C=\\{c_1, c_2, c_3, ... c_j\\}$\n",
    "\n",
    "**Output:**\n",
    "* predicted class $c \\in C$\n",
    "\n",
    "Existing classifiers that can be used are naive Bayes, logistic regression, support-vector machines, k-nearest neighbours, classification tree, random forest, ...\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "One of the simplest classification methods based on a Bayes rule. It assumes features independence and therefore it can lack performance (e.g. XOR problem).\n",
    "\n",
    "$$\n",
    "P(c|d) = \\frac{P(d|c)P(c)}{P(d)} \\\\\n",
    "c_{MAP} = \\textrm{argmax}_{c \\in C}P(c|d) = \\textrm{argmax}_{c \\in C}P(d|c)P(c)\n",
    "$$\n",
    "\n",
    "For the classification we need to define the features - i.e. representation of an input document for a classifier. A simple approach would be to use a bag of words representation:\n",
    "\n",
    "<img src=\"bow1.png\" width=\"400\"> <img src=\"bow2.png\" width=\"400\">\n",
    "\n",
    "$$\n",
    "c_{MAP} = \\textrm{argmax}_{c \\in C}P(x_1, x_2, x_3, ..., x_n|c)P(c) \\\\\n",
    "c_{MAP} = \\textrm{argmax}_{c \\in C}P(x_1|c)P(x_2|c)P(x_3) ... P(x_n|c)P(c)\n",
    "$$\n",
    "\n",
    "Generally we need to classify examples into one of the multiple classes, therefore a  *multinomial* naive Bayes classifier is defined as:\n",
    "\n",
    "$$\n",
    "c_{NB} = \\textrm{argmax}_{c_j \\in C} P(c_j) \\prod_{i \\in \\textrm{features}} P(x_i|c_j)\n",
    "$$\n",
    "\n",
    "Basic code in Python:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "##################\n",
    "### PSEUDOCODE ###\n",
    "##################\n",
    "\n",
    "# 1. Load data\n",
    "# 2. Prepare features\n",
    "features = []\n",
    "classes = []\n",
    "\n",
    "for example in examples:\n",
    "    item = []\n",
    "\n",
    "    # Our features (an idea)\n",
    "    item.append(hasLink(example))\n",
    "    item.append(frequency5w1h(example))\n",
    "    item.append(numberOfEmoticons(example))\n",
    "    item.append(numberOfUnicodeEmoticons(example))\n",
    "    item.append(numberOfInterjections(example))\n",
    "    item.append(containtsCapsWord(example))\n",
    "    item.append(verbPos(example))\n",
    "    item.append(numberOfNegations(example))\n",
    "    item.append(hasFutureVerb(example))\n",
    "    item += [hasPunctuations(example)[key] for key in punctuationKeys]\n",
    "    item.append(containsOneOf_5w1h(example))\n",
    "    item.append(textLength(example['tokens']))\n",
    "    item.append(textUniqueLength(example['tokens']))\n",
    "    item.append(textStemmedLength(example['tokens']))\n",
    "    item.append(textStemmedUniqueLength(example['tokens']))\n",
    "    item.append(postPos(example, examples))\n",
    "    item.append(sentencePos(example, examples))\n",
    "    item.append(hasQuestionmark(example))\n",
    "    item.append(hasExclamationMark(example))\n",
    "    item.append(hasThank(example))\n",
    "    item.append(hasPositiveFeedback(example))\n",
    "    item.append(sentimentValue(example))\n",
    "    item.append(sentenceNormPos(example, examples))\n",
    "    item.append(hasDuplicateWords(example))\n",
    "    item.append(isQuote(example, examples))\n",
    "    item.append(conversationSim(example, examples))\n",
    "    item.append(initSim(example, examples))\n",
    "\n",
    "    features.append(item)\n",
    "    classes.append(example['class'])\n",
    "\n",
    "(X, y) = (np.array(features), np.array(classes))\n",
    "print((\"Dataset shape: {}\".format((X.shape, y.shape))))\n",
    "\n",
    "# 3. Define classifier\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "\n",
    "# 4. Train a classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluate (cross-validation)\n",
    "scorings = [\"accuracy\", \"precision_weighted\", \"recall_weighted\", \"f1_weighted\"]\n",
    "for scoring in scorings:\n",
    "    scores = cross_val_score(clf, X, y, cv=10, scoring=scoring)\n",
    "\n",
    "# 6. Predict using a classifier\n",
    "pred = clf.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Classification of documents from 20 newsgroups dataset. Scikit-learn will download and cache the dataset in your home folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2034, training features: 26576\n",
      "Testing samples: 1353, Testing features: 26576\n",
      "Training ...\n",
      "Testing ...\n",
      "Classification accuracy:   0.788\n",
      "Classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.69      0.67      0.68       319\n",
      "     comp.graphics       0.92      0.89      0.90       389\n",
      "         sci.space       0.80      0.90      0.85       394\n",
      "talk.religion.misc       0.69      0.60      0.64       251\n",
      "\n",
      "          accuracy                           0.79      1353\n",
      "         macro avg       0.77      0.77      0.77      1353\n",
      "      weighted avg       0.79      0.79      0.79      1353\n",
      "\n",
      "Confusion matrix:\n",
      "[[214   7  36  62]\n",
      " [  9 347  31   2]\n",
      " [ 18  18 354   4]\n",
      " [ 71   7  22 151]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "\n",
    "# Loading 20 newsgroups dataset for categories\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "\n",
    "target_names = data_train.target_names\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "# Extracting features from the data using a sparse vectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "print(\"Training samples: %d, training features: %d\" % X_train.shape)\n",
    "print(\"Testing samples: %d, Testing features: %d\" % X_test.shape)\n",
    "\n",
    "# Training and testing a Multinomial naive Bayes\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "\n",
    "print(\"Training ...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Testing ...\")\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Classification accuracy:   %0.3f\" % score)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "# Show confusion matrix\n",
    "print(\"Confusion matrix:\")\n",
    "cm = metrics.confusion_matrix(y_test, pred)\n",
    "print(cm)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance measures\n",
    "\n",
    "Most common general measures for the classification methods in the machine learning are classification accuracy, precision, recall and F-score. \n",
    "\n",
    "Let's imagine we have a problem with two target classes. We would calculate performance of our classifier as follows:\n",
    "\n",
    "| - |Correct  |Not Correct  |\n",
    "|-------------|:-------:|:-----------:|\n",
    "|Selected     |TP       | FP          |\n",
    "|Not selected |FN       | TN          |\n",
    "\n",
    "Classification accuracy:\n",
    "$$\n",
    "\\textrm{CA} = \\frac{\\textrm{TP}+\\textrm{TN}}{\\textrm{TP}+\\textrm{FP}+\\textrm{FN}+\\textrm{TN}}\n",
    "$$\n",
    "\n",
    "Precision or Sensitivity: a proportion of selected items that are correct (in medical terms probability of being test positive when disease present)\n",
    "$$\n",
    "\\textrm{P} = \\textrm{Sensitivity} = \\frac{\\textrm{TP}}{\\textrm{TP}+\\textrm{FP}}\n",
    "$$\n",
    "\n",
    "Recall: a proportion of correct items that are selected\n",
    "$$\n",
    "\\textrm{R} = \\frac{\\textrm{TP}}{\\textrm{TP}+\\textrm{FN}}\n",
    "$$\n",
    "\n",
    "Specificity: a proportion of not correct items that are not selected (in medical terms probability of being test negative when disease absent)\n",
    "$$\n",
    "\\textrm{Specificity} = \\frac{\\textrm{TN}}{\\textrm{FP}+\\textrm{TN}}\n",
    "$$\n",
    "\n",
    "F (i.e. $F_1$) measure: a harmonic mean (i.e., very conservative average) between precision and recall\n",
    "$$\n",
    "\\textrm{F} = \\frac{(\\beta^2+1)\\textrm{PR}}{\\beta^2\\textrm{P}+\\textrm{R}}; \\textrm{F}_1 = \\frac{2\\textrm{PR}}{\\textrm{P}+\\textrm{R}}\n",
    "$$\n",
    "\n",
    "If we have a multi-class problem, we need to take this into account also for the evaluation:\n",
    "* Macro-averaging: compute performance for each class, then average\n",
    "* Micro-averaging: collect decisions for all classes, compute contingency table, evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Micro- and macro-averages (for any metric) will compute slightly different things, and thus their interpretation differs:\n",
    "\n",
    "A macro-average will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes).\n",
    "\n",
    "An example:\n",
    "\n",
    "| Class | TP | FP | FN | Precision | Recall | F-score |\n",
    "|:-----:|:--:|:--:|:--:|:---------:|:------:|:------:|\n",
    "| A     | 5  | 2  | 1  | 0.71      | 0.83   | 0.76 |\n",
    "| B     | 10 | 90 | 7  | 0.1       | 0.58   | 0.17 |\n",
    "| C     | 15 | 11 | 2  | 0.57      | 0.88   | 0.69 |\n",
    "\n",
    "$$\n",
    "\\textrm{P}_{micro} = \\frac{\\textrm{TP}_A + \\textrm{TP}_B + \\textrm{TP}_C}{\\textrm{TP}_A + \\textrm{TP}_B + \\textrm{TP}_C + \\textrm{FP}_A + \\textrm{FP}_B + \\textrm{FP}_C} = 0.22\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{P}_{macro} = \\frac{\\textrm{P}_A + \\textrm{P}_B + \\textrm{P}_C}{3} = 0.46\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{R}_{micro} = \\frac{\\textrm{TP}_A + \\textrm{TP}_B + \\textrm{TP}_C}{\\textrm{TP}_A + \\textrm{TP}_B + \\textrm{TP}_C + \\textrm{FN}_A + \\textrm{FN}_B + \\textrm{FN}_C} = 0.75\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{R}_{macro} = \\frac{\\textrm{R}_A + \\textrm{R}_B + \\textrm{R}_C}{3} = 0.76\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{F}_{micro} = accuracy = \\frac{TP}{TP + \\frac{1}{2}*(FP+FN)} = 0.35\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{F}_{macro} = \\frac{\\textrm{F}_A + \\textrm{F}_B + \\textrm{F}_C}{3} = 0.54\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{F}_{weighted} = \\frac{6*\\textrm{F}_A + 17*\\textrm{F}_B + 17*\\textrm{F}_C}{6+17+17} = 0.48\n",
    "$$\n",
    "\n",
    "F micro-averaging essentially computes the **proportion of correctly classified observations** out of all observations. If we think about this, this definition is in fact what we use to calculate overall **accuracy**.\n",
    "\n",
    "\n",
    "In general, if you are working with an imbalanced dataset where all classes are equally important, using the **macro average** would be a good choice as it treats all classes equally.\n",
    "\n",
    "If you have an imbalanced dataset but want to assign greater contribution to classes with more examples in the dataset, then the **weighted average** is preferred.\n",
    "\n",
    "Suppose you have a balanced dataset and want an easily understandable metric for overall performance regardless of the class. In that case, you can go with accuracy, which is essentially our **micro F1 score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the scores for the example above\n",
    "\n",
    "def f1_micro():\n",
    "    pass\n",
    "\n",
    "def f1_macro():\n",
    "    pass\n",
    "\n",
    "def f1_weighted():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instead of TF-IDF features for the example above, do feature \n",
    "# engineering by yourself (e.g., based on pseudocode) and \n",
    "# compare results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Experiment with *20 newsgroups* dataset on your own (manually download and import, remove headers, adjust parameters, train and test on the same data :), ...).\n",
    "* Experiment with other classifiers: Logistic regression, Random forest, SVM, ...\n",
    "* Implement your own features.\n",
    "* Try to play with some other dataset or create your own. For example, use [Reuters-21578](http://www.daviddlewis.com/resources/testcollections/reuters21578/) - example [here](http://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-text-classification-1.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
