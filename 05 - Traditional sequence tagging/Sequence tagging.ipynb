{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional sequence tagging\n",
    "\n",
    "<sup>This notebook is a part of Natural Language Processing class at the University of Ljubljana, Faculty for computer and information science. Please contact [slavko.zitnik@fri.uni-lj.si](mailto:slavko.zitnik@fri.uni-lj.si) for any comments.</sub>\n",
    "\n",
    "In machine-learning we can divide the classification models into two groups:\n",
    "\n",
    "* Joint (generative) models - calculate probabilities over both observed and hidden data.\n",
    "    * A model gives the probabilities P(c,d) and tries to maximize . \n",
    "    * Examples of such models are: naive Bayes, hidden Markov models, n-gram models.\n",
    "* Discriminative (conditional) models - take the data as given and calculate probability over hidden structure (P(c|d)). Examples of such models are:\n",
    "    * logistic regression, conditional (or maximum entropy) models, conditional random fields\n",
    "    * also SVM, averaged perceptron, ... (but not directly probabilistic)\n",
    "    \n",
    "<img src=\"generativeVsDiscriminative.png\" width=\"400px\" />\n",
    "\n",
    "In NLP, IR and speech processing we mostly use the conditional ones because:\n",
    "* they will achieve better performance,\n",
    "* they make it easy to incorporate lots of features,\n",
    "* they allow for building language independent and reusable components.\n",
    "\n",
    "Conditional models work well. Even with the same features as a joint model, a conditional estimation increases performance. An illustrative example on the task of word sense disambiguation (Klein and Manning, 2002):\n",
    "\n",
    "| Objective     | Train data (CA)| Test data (CA) |\n",
    "| ------------- |:--------------:|:--------------:|\n",
    "| Joint         | 86.8           | 73.6           |\n",
    "| Conditional   | **98.5**       | **76.1**       |\n",
    "\n",
    "For those who are more interested and would like to better understand the ideas behind sequence tagging techniques, I propose to watch videos by Jurafsky and Manning that were used for their NLP Coursera course (relevant for this topic are sections 8,9,11 and 12)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Models\n",
    "\n",
    "The often cited source source of Hidden Markov Models is Rabiner's paper *A tutorial on Hidden Markov Models and Selected Applications in Speech Recognition* (1989).\n",
    "\n",
    "An HMM is specified by the following components:\n",
    "* a set of states $Q$ (along with special start and end state $q_0,q_{end}$ that are not associated with observation)\n",
    "\n",
    "$$\n",
    "Q=q_1q_2\\ldots q_N\n",
    "$$\n",
    "\n",
    "* a set of observations $O$\n",
    "\n",
    "$$\n",
    "O=o_1o_2\\ldots o_N\n",
    "$$\n",
    "\n",
    "* a transition probability matrix $A$ (each $a_{ij}$ represents the probability of moving from state $i$ to state $j$, $\\sum_{j=1}^{n} a_{ij} = 1\\;\\;\\forall i$)\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "    a_{01} & a_{02} & a_{03} & \\dots  & a_{0n} \\\\\n",
    "    a_{11} & a_{12} & a_{13} & \\dots  & a_{1n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    a_{n1} & a_{n2} & a_{n3} & \\dots  & a_{nn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* a set of observation likelihoods (i.e., emission probabilities that express the probability of an observation $o_t$ being generated from state $i$)\n",
    "\n",
    "$$\n",
    "B=b_i(o_t)\n",
    "$$\n",
    "\n",
    "The algorithm is used to predict sequences of data using two simplifying assumptions. If we focus on first-order Markov chain, then the probability of a particular state is dependent only on the previous state:\n",
    "\n",
    "$$\n",
    "P(q_i|q_1\\ldots q_{i-1}) = P(q_i|q_{i-1})\n",
    "$$\n",
    "\n",
    "Second, the probability of an output observation $o_i$ is dependent only on the state that produced observation $q_i$:\n",
    "\n",
    "$$\n",
    "P(o_i|q_1\\ldots q_i,\\ldots q_n,o_1,\\ldots o_i,\\ldots o_n) = P(o_i|q_i)\n",
    "$$\n",
    "\n",
    "A specific tag in a sequence is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\hat{T} = \\textrm{argmax}_T\\; \\prod_i P(\\textrm{word}_i|\\textrm{tag}_i) \\prod_i P(\\textrm{tag}_i|\\textrm{tag}_{i-1})\n",
    "$$\n",
    "\n",
    "Therefore, the probability of the whole sequence of states is calculated as follows:\n",
    "\n",
    "$$\n",
    "P(Q|O) = \\prod_{i=1}^n P(o_i|q_i) \\times \\prod_{i=1}^n P(q_i|q_{i-1})\n",
    "$$\n",
    "\n",
    "To enable solving tagging problems using an HMM, three tasks needs to be implemented:\n",
    "* Computing likelihood (the forwards algorithm): Given an HMM $\\lambda=(A,B)$ and an observation sequence $O$, determine the likelihood $P(O|\\lambda)$.\n",
    "* Decoding (the viterbi algorithm): Given an observation sequence O and an HMM $\\lambda=(A,B)$, discover the best hidden state sequence $Q$.\n",
    "* Learning (the forward-backward or Baum-Welch algorithm): Given an observation sequence $O$ and the set of states in the HMM, learn the HMM parameters $A$ and $B$. \n",
    "\n",
    "### An HMM example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/slavkoz/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"treebank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of training data:\n",
      "\t[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "\n",
      "Tagger info:\n",
      "\t<HiddenMarkovModelTagger 46 states and 10779 output symbols>\n",
      "\n",
      "Tagger symbols (first 100):\n",
      "\t['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.', 'Mr.', 'is', 'chairman', 'of', 'Elsevier', 'N.V.', 'Dutch', 'publishing', 'group', 'Rudolph', 'Agnew', '55', 'and', 'former', 'Consolidated', 'Gold', 'Fields', 'PLC', 'was', 'named', '*-1', 'this', 'British', 'industrial', 'conglomerate', 'A', 'form', 'asbestos', 'once', 'used', '*', 'to', 'make', 'Kent', 'cigarette', 'filters', 'has', 'caused', 'high', 'percentage', 'cancer', 'deaths', 'among', 'workers', 'exposed', 'it', 'more', 'than', '30', 'ago', 'researchers', 'reported', '0', '*T*-1', 'The', 'fiber', 'crocidolite', 'unusually', 'resilient', 'enters', 'lungs', 'with', 'even', 'brief', 'exposures', 'causing', 'symptoms', 'that', 'show', 'up', 'decades', 'later', 'said', '*T*-2', 'Lorillard', 'Inc.', 'unit', 'New', 'York-based', 'Loews', 'Corp.', 'makes', 'cigarettes']\n",
      "\n",
      "Tagger states:\n",
      "\t['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.', 'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '-NONE-', 'RB', 'TO', 'PRP', 'RBR', 'WDT', 'VBP', 'RP', 'PRP$', 'JJS', 'POS', '``', 'EX', \"''\", 'WP', ':', 'JJR', 'WRB', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS', 'FW', 'UH', 'SYM', 'LS', '#']\n",
      "\n",
      "\n",
      "Classification accuracy on TRAINING DATA: 0.98\n",
      "\n",
      "\n",
      "Test data size: 914\n",
      "Classification accuracy on TEST DATA (our model): 0.37\n",
      "Classification accuracy on TEST DATA (NLTK tagger): 0.9\n",
      "\n",
      "\n",
      "Example 0:\n",
      "\tOur tagger: [('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "\tNLTK tagger: [('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "\n",
      "Example 1:\n",
      "\tOur tagger: [('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "\tNLTK tagger: [('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "\n",
      "Example 2:\n",
      "\tOur tagger: [('We', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('master', 'NN'), ('the', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Tools', 'NNP'), ('.', 'NNP')]\n",
      "\tNLTK tagger: [('We', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('master', 'VB'), ('the', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Tools', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk.tag import hmm\n",
    "\n",
    "# Training data\n",
    "train_data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:6000]\n",
    "\n",
    "print(\"An example of training data:\\n\\t{}\\n\".format(train_data[0]))\n",
    "\n",
    "# Setup a trainer with default parameters and train a tagger\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_data)\n",
    "\n",
    "# Print some tagger properties\n",
    "print(\"Tagger info:\\n\\t{}\\n\".format(tagger))\n",
    "print(\"Tagger symbols (first 100):\\n\\t{}\\n\".format(tagger._symbols[:100]))\n",
    "print(\"Tagger states:\\n\\t{}\\n\".format(tagger._states))\n",
    "\n",
    "print(\"\\nClassification accuracy on TRAINING DATA: {:.2}\\n\".format(tagger.accuracy(train_data)))\n",
    "\n",
    "print(f\"\\nTest data size: {len(test_data)}\")\n",
    "print(\"Classification accuracy on TEST DATA (our model): {:.2}\".format(tagger.accuracy(test_data)))\n",
    "print(\"Classification accuracy on TEST DATA (NLTK tagger): {:.2}\\n\".format(nltk.tag._get_tagger(\"eng\").accuracy(test_data)))\n",
    "\n",
    "# Tag new sentences\n",
    "example = [word for word, pos in train_data[0]]\n",
    "print(\"\\nExample 0:\\n\\tOur tagger: {}\\n\\tNLTK tagger: {}\".format(tagger.tag(example), nltk.pos_tag(example)))\n",
    "\n",
    "example = \"Today is a good day .\".split()\n",
    "print(\"\\nExample 1:\\n\\tOur tagger: {}\\n\\tNLTK tagger: {}\".format(tagger.tag(example), nltk.pos_tag(example)))\n",
    "\n",
    "example = \"We are going to master the Natural Language Processing Tools .\".split()\n",
    "print(\"\\nExample 2:\\n\\tOur tagger: {}\\n\\tNLTK tagger: {}\".format(tagger.tag(example), nltk.pos_tag(example)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional (or Maximum Entropy) Markov Models\n",
    "\n",
    "Let's start first with the maximum entropy classifier (MaxEnt), which is basically a multinomial logistic regression classifier. The classifier belongs to a group of exponential or log-linear classifiers. MaxEnt works by extracting some set of features from the input, combining them linearly (t.i., multiply each by a weight and then add them up), and then using this sum as an exponent.\n",
    "\n",
    "A feature for tagging might be *\"this word ends in -ing\"* or *\"the previous word was Mr.\"*. For each feature $f_i$, we need to have some weight $w_i$:\n",
    "\n",
    "$$\n",
    "p(c|x) = \\frac{e^{\\sum_iw_if_i}}{Z} = \\frac{\\mathrm{exp}(\\sum_iw_if_i)}{Z}\n",
    "$$\n",
    "\n",
    "Let's say we have $N$ features and $C$ classes $\\{c_1,c_2\\ldots c_C\\}$:\n",
    "\n",
    "$$\n",
    "p(c|x) = \\frac{\\mathrm{exp}(\\sum_{i=0}^{N}w_{ci}f_i(c,x))} {\\sum_{c'\\in C}\\mathrm{exp}(\\sum_{i=0}^{N}w_{c'i}f_i(c',x))}\n",
    "$$\n",
    "\n",
    "We are still doing the standard classification, so $x$ may be one token (e.g., word) in a sequence. Now we need to define some feature functions, for example:\n",
    "\n",
    "$$\n",
    "f_1(c,x) =  \n",
    "\\begin{cases} \n",
    "      1 & \\textrm{if}\\;x=\\textrm{\"Mirko\"}\\;\\&\\;c = \\textrm{ PER} \\\\\n",
    "      0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_2(c,x) =  \n",
    "\\begin{cases} \n",
    "      1 & \\textrm{if POS tag of }\\;x=\\textrm{\"Noun\"} \\\\\n",
    "      0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_3(c,x) =  \n",
    "\\begin{cases} \n",
    "      1 & \\textrm{if word }\\;x\\;\\textrm{ starts with upper case} \\\\\n",
    "      0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_4(c,x) =  \n",
    "\\begin{cases} \n",
    "      1 & \\textrm{if word before }\\;x=\\textrm{\"Mr.\"}\\;\\&\\;c = \\textrm{ PER} \\\\\n",
    "      0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_5(c,x) =  \n",
    "\\begin{cases} \n",
    "      1 & \\textrm{if word before }\\;x=\\textrm{\"Mr.\"}\\;\\&\\;c = \\textrm{ ORG} \\\\\n",
    "      0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_6(c,x) =  \n",
    "\\begin{cases} \n",
    "      1 & \\textrm{if word }\\;x=\\textrm{ appears in the list of organizations}\\;\\&\\;c = \\textrm{ ORG} \\\\\n",
    "      0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Now we would train the model and get weights for all of the features regarding the classes. Let's have an example sentence \"Dr. Mirko and Mr. Slavko are working at Fušarija Inc.\". Now we are interested in the word \"Slavko\", so according to it, we can populate the following table (note, we still use token-level MaxEnt):\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcccccc}\n",
    " &1&2&3&4&5&6 \\\\ \\hline\n",
    "f_i(\\textrm{\"ORG\"}, \\textrm{\"Slavko\"})&0&1&1&0&1&0 \\\\ \\hline\n",
    "w_{\\textrm{\"ORG\"}i}&&.9&1.1&&-.2& \\\\ \\hline\n",
    "f_i(\\textrm{\"PER\"}, \\textrm{\"Slavko\"})&0&1&1&1&0&0 \\\\ \\hline\n",
    "w_{\\textrm{\"PER\"}i}&&.7&.9&.95&& \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "According to the above, we can calculate the following probabilities:\n",
    "\n",
    "$$\n",
    "P(\\textrm{\"ORG\"}|\\textrm{\"Slavko\"}) = \\frac{e^{.9}e^{1.1}e^{-.2}}{e^{.9}e^{1.1}e^{-.2}+e^{.7}e^{.9}e^{.95}} \\approx \\frac{6.05}{18.86} \\approx 0.32\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\textrm{\"PER\"}|\\textrm{\"Slavko\"}) = \\frac{e^{.7}e^{.9}e^{.95}}{e^{.9}e^{1.1}e^{-.2}+e^{.7}e^{.9}e^{.95}} \\approx \\frac{12.81}{18.86} \\approx 0.68\n",
    "$$\n",
    "\n",
    "Now we can perform classification using formula \n",
    "\n",
    "$$\n",
    "\\hat{c} = \\textrm{argmax}_{c\\in C}\\;P(c|x),\n",
    "$$\n",
    "\n",
    "which results that the word \"Slavko\" in the above sequence is classified as a person (i.e. *PER*).\n",
    "\n",
    "Now we want a such classifier to predict sequences of classes and not classes of tokens separately. Using a combination of MaxEnt and HMM, we can achieve this using MaxEnt and VIterbi. As we know, Maximum Entropy Models compute $P(T|W)$ directly in one model and does not rely on a Bayes rule ($P(W|T)P(W)$), as it is discriminative model rather than generative. A specific tag in a sequence is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\hat{T} = \\textrm{argmax}_T\\;\\prod_i P(\\textrm{tag}_i|\\textrm{word}_i,\\textrm{tag}_{i-1})\n",
    "$$\n",
    "\n",
    "Therefore, the probability of a sequence of states is calculated as follows:\n",
    "\n",
    "$$\n",
    "P(Q|O)=\\prod_{i=1}^n P(q_i|q_{i-1},o_i)\n",
    "$$\n",
    "\n",
    "An example of using the NLTK's MaxentClassifier along with Viterbi to achieve the functionality of MEMMs is available in the following repository: [https://github.com/yh1008/MEMM](https://github.com/yh1008/MEMM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Random Fields\n",
    "\n",
    "CRFs is another sequence model, but before we present it, let's look back to HMMs and MEMMs.\n",
    "\n",
    "CRFs and MEMMS are discriminative sequence models whereas HMMs are generative sequence models. HMM essentially uses Bayes Rule as a local model over the transition and emission probabilities, whereas CRF and MEMM's local models are MaxEnt models over transition and observable features. \n",
    "\n",
    "The biggest disadvantage of HMMs is that it is hard to represent the data in a form to use many features. MEMMs solves this by using many features but still remains locally normalized, which results in [a label bias problem](https://awni.github.io/label-bias/). The CRFs solves the problem by globaly normalizing against the whole sequence. CRFs is therefore widely used and applied and gives state-the-art results in many domains.\n",
    "\n",
    "For more info, see a nice presentation in *From_HMM_to_CRF.ppt*.\n",
    "\n",
    "The CRF model is represented as\n",
    "\n",
    "$$\n",
    "P(c|d,\\lambda) = \\frac{\\textrm{exp}\\sum_i\\lambda_if_i(c,d)}{\\sum_{c'}\\textrm{exp}\\sum_i\\lambda_if_i(c',d)},\n",
    "$$\n",
    "\n",
    "where the space of $c'$s is now the space of all possible sequences.\n",
    "\n",
    "### A CRF example\n",
    "\n",
    "NLTK library does not include a CRF implementation but it provides an interface to a widely and efficient C++ implementation [CRFSuite](http://www.chokkan.org/software/crfsuite/). \n",
    "\n",
    "#### How to use a CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "##################\n",
    "### PSEUDOCODE ###\n",
    "##################\n",
    "\n",
    "# 1. Define feature functions\n",
    "def getFeatures(tokens, idx):\n",
    "    token = tokens[idx]\n",
    "\n",
    "    feature_list = []\n",
    "\n",
    "    # Capitalization\n",
    "    if containtsCapsWord(token):\n",
    "        feature_list.append('CAPS_WORD')\n",
    "\n",
    "    # Number\n",
    "    if sum([re.search(num_pattern, token) is not None for token in tokens]) > 0:\n",
    "        feature_list.append('HAS_NUM')\n",
    "\n",
    "    if textUniqueLength(tokens) < 5:\n",
    "        feature_list.append('SHORT')\n",
    "\n",
    "    if containsOneOf_5w1h(token) == 1:\n",
    "        feature_list.append('5W1H')\n",
    "\n",
    "    if hasQuestionmark(token) == 1:\n",
    "        feature_list.append(\"QUESTION\")\n",
    "\n",
    "    if hasThank(token) == 1:\n",
    "        feature_list.append(\"THANK\")\n",
    "\n",
    "    if hasExclamationMark(token) == 1:\n",
    "        feature_list.append(\"EXCLAMATION\")\n",
    "\n",
    "    if hasPositiveFeedback(token) == 1:\n",
    "        feature_list.append(\"POS_FEED\")\n",
    "\n",
    "    if hasDuplicateWords(token) == 1:\n",
    "        feature_list.append(\"DUPLIC\")\n",
    "\n",
    "    feature_list.append(\"SENT=\" + str(sentimentValue(token)))\n",
    "\n",
    "    # TOP TFIDF LEMMAS\n",
    "    for (lemma, _) in topNtfidfLemmas(token, 5):\n",
    "        feature_list.append(\"LEMMA=\" + lemma)\n",
    "\n",
    "    if hasLink(token) == 1:\n",
    "        feature_list.append(\"LINK\")\n",
    "\n",
    "    if hasPunctuations(token)[\":\"] == 1:\n",
    "        feature_list.append(\"COLON\")\n",
    "\n",
    "    if hasPunctuations(token)[\"..\"] == 1:\n",
    "        feature_list.append(\"DOTS\")\n",
    "\n",
    "    if numberOfEmoticons(token) > 0:\n",
    "        feature_list.append(\"EMOTICONS\")\n",
    "\n",
    "    if numberOfUnicodeEmoticons(token) > 0:\n",
    "        feature_list.append(\"U_EMOTICONS\")\n",
    "\n",
    "    if numberOfInterjections(token) > 0:\n",
    "        feature_list.append(\"INTERJECTIONS\")\n",
    "\n",
    "    if verbPos(token) == -1:\n",
    "        feature_list.append(\"NO_VERB\")\n",
    "    elif verbPos(token) == 0:\n",
    "        feature_list.append(\"VERB_FIRST\")\n",
    "    elif verbPos(token) == len(token[\"tokens\"]) - 1:\n",
    "        feature_list.append(\"VERB_LAST\")\n",
    "    else:\n",
    "        feature_list.append(\"VERB_MIDDLE\")\n",
    "\n",
    "    for (modal, f) in zip(modals, modalsFunctionGenerator()):\n",
    "        if f(token) > 0:\n",
    "            feature_list.append(\"MODAL=\" + modal)\n",
    "\n",
    "    if numberOfNegations(token) > 0:\n",
    "        feature_list.append(\"NEG\")\n",
    "\n",
    "    if hasFutureVerb(token) == 1:\n",
    "        feature_list.append(\"FUTURE\")\n",
    "\n",
    "    if verbTense(token)[\"hasPastV\"] == 1:\n",
    "        feature_list.append(\"TENSE=hasPastV\")\n",
    "\n",
    "    if verbTense(token)[\"hasIngV\"] == 1:\n",
    "        feature_list.append(\"TENSE=hasIngV\")\n",
    "\n",
    "    if verbTense(token)[\"hasImperativeV\"] == 1:\n",
    "        feature_list.append(\"TENSE=hasImperativeV\")\n",
    "\n",
    "    if pronominalCues(token)[\"has_1stperson_sg\"] > 0:\n",
    "        feature_list.append(\"PRONOMINAL=has_1stperson_sg\")\n",
    "\n",
    "    if pronominalCues(token)[\"has_1stperson_pl\"] > 0:\n",
    "        feature_list.append(\"PRONOMINAL=has_1stperson_pl\")\n",
    "\n",
    "    if pronominalCues(token)[\"has_2ndperson\"] > 0:\n",
    "        feature_list.append(\"PRONOMINAL=has_2ndperson\")\n",
    "\n",
    "    if pronominalCues(token)[\"has_3rdperson\"] > 0:\n",
    "        feature_list.append(\"PRONOMINAL=has_3rdperson\")\n",
    "\n",
    "    return feature_list\n",
    "\n",
    "# 2. Prepare data\n",
    "data = []\n",
    "for post in getAllPosts(examples):\n",
    "    data.append([(example, str((example['class']))) for example in post])\n",
    "\n",
    "# 3. Prepare data for training (and testing if needed)\n",
    "random.shuffle(data)\n",
    "n_test_samples = int(0.3 * len(data))\n",
    "train_data = data[:-n_test_samples]\n",
    "test_data = data[-n_test_samples:]\n",
    "\n",
    "# 4. Train a classifier (built classifier will be stored into a file \"model.crf.tagger\")\n",
    "ct = CRFTagger(feature_func=getFeatures, verbose=True, training_opt={})\n",
    "ct.train(train_data, \"model.crf.tagger\")\n",
    "\n",
    "# 5. Evaluate classifier\n",
    "print(ct.evaluate(test_data))\n",
    "\n",
    "# 6. Tag new sequences\n",
    "print(ct.tag(test_data[0]))\n",
    "\n",
    "# When we have already trained a model and would just like to tag new data\n",
    "ct = CRFTagger(feature_func=getFeatures, verbose=True, training_opt={})\n",
    "ct.set_model_file(\"model.crf.tagger\")\n",
    "print(ct.tag(test_data[0])`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple CRF for part-of-speech tagging\n",
    "\n",
    "What are the feature functions used in the example below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of training data:\n",
      "\t[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "\n",
      "\n",
      "Classification accuracy on TRAINING DATA: 0.96\n",
      "\n",
      "\n",
      "Test data size: 914\n",
      "Classification accuracy on TEST DATA (our model): 0.95\n",
      "\n",
      "Example 0:\n",
      "\tOur tagger: [('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "\tNLTK tagger: [('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "\n",
      "Example 1:\n",
      "\tOur tagger: [('Today', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "\tNLTK tagger: [('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "\n",
      "Example 2:\n",
      "\tOur tagger: [('We', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('master', 'VB'), ('the', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Tools', 'NNP'), ('.', '.')]\n",
      "\tNLTK tagger: [('We', 'PRP'), ('are', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('master', 'VB'), ('the', 'DT'), ('Natural', 'NNP'), ('Language', 'NNP'), ('Processing', 'NNP'), ('Tools', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from nltk.tag import crf\n",
    "\n",
    "# Training data\n",
    "train_data = treebank.tagged_sents()[:3000]\n",
    "test_data = treebank.tagged_sents()[3000:6000]\n",
    "print(\"An example of training data:\\n\\t{}\\n\".format(train_data[0]))\n",
    "\n",
    "# Setup a trainer with default parameters and train a tagger\n",
    "tagger = crf.CRFTagger()\n",
    "tagger.train(train_data, \"model.crf.tagger\")\n",
    "\n",
    "print(\"\\nClassification accuracy on TRAINING DATA: {:.2}\\n\".format(tagger.accuracy(train_data)))\n",
    "\n",
    "print(f\"\\nTest data size: {len(test_data)}\")\n",
    "print(\"Classification accuracy on TEST DATA (our model): {:.2}\".format(tagger.accuracy(test_data)))\n",
    "\n",
    "# Tag new sentences\n",
    "example = [word for word, pos in train_data[0]]\n",
    "print(\"\\nExample 0:\\n\\tOur tagger: {}\\n\\tNLTK tagger: {}\".format(tagger.tag(example), nltk.pos_tag(example)))\n",
    "\n",
    "example = \"Today is a good day .\".split()\n",
    "print(\"\\nExample 1:\\n\\tOur tagger: {}\\n\\tNLTK tagger: {}\".format(tagger.tag(example), nltk.pos_tag(example)))\n",
    "\n",
    "example = \"We are going to master the Natural Language Processing Tools .\".split()\n",
    "print(\"\\nExample 2:\\n\\tOur tagger: {}\\n\\tNLTK tagger: {}\".format(tagger.tag(example), nltk.pos_tag(example)))\n",
    "\n",
    "# Where are the feature functions here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above shows the use of NLTK's CRFSuite wrapper - [python-crfsuite library](https://python-crfsuite.readthedocs.io/en/latest/). In the library's documentation you can find an example of how to use the library directly - [jupyter notebook](https://github.com/scrapinghub/python-crfsuite/blob/master/examples/CoNLL%202002.ipynb).\n",
    "\n",
    "*NOTE:* If you get an error '*NameError: name 'pycrfsuite' is not defined*,' remove try/except block around the pycrfsuite import in the '.venv/lib/python3.10/site-packages/nltk/tag/crf.py'. After that reset kernel and re-run. More info: [https://github.com/nltk/nltk/issues/3019](https://github.com/nltk/nltk/issues/3019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try to do the following on your own:\n",
    "* Implement your own HMM classifier based on the Rabiner's tutorial.\n",
    "* Adjust the number of training sequences for the HMM POS tagger and observe differences.\n",
    "* Try some CRF parameters - e.g., verbose, feature_func, training_opt.\n",
    "* Try to implement named entity recognition on the ssj500k dataset for slovene (according to the paper [Razpoznavanje imenskih entitet v slovenskem jeziku, Štajner in sod. (2013)](http://revije.ff.uni-lj.si/slovenscina2/article/download/6926/6620)).\n",
    "* Find your own sequence tagging problem and try it - for example, see CoNLL tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
